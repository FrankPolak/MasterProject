{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "\n",
    "from utils import prepare_data\n",
    "from build_model import Autoencoder_5_Layers, Autoencoder_4_Layers, Autoencoder_3_Layers\n",
    "from train_model import train_autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device agnostic\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Import data\n",
    "DNA_meth_train = prepare_data(\"../Data/DNAMethylation_train.csv\")\n",
    "DNA_meth_test = prepare_data(\"../Data/DNAMethylation_test.csv\")\n",
    "RNA_seq_train = prepare_data(\"../Data/RNAseq_train.csv\")\n",
    "RNA_seq_test = prepare_data(\"../Data/RNAseq_test.csv\")\n",
    "\n",
    "# k-means\n",
    "dna_methylation = prepare_data(\"../Data/DNAMethylation.csv\", transpose=True, normalise=True)\n",
    "rna_seq = prepare_data(\"../Data/RNAseq.csv\", transpose=True, normalise=True)\n",
    "\n",
    "# Merge\n",
    "X_train = pd.merge(DNA_meth_train, RNA_seq_train, left_index=True, right_index=True)\n",
    "X_test = pd.merge(DNA_meth_test, RNA_seq_test, left_index=True, right_index=True)\n",
    "\n",
    "data = pd.merge(dna_methylation, rna_seq, left_index=True, right_index=True)\n",
    "\n",
    "# Convert to tensors and send to device\n",
    "X_train = torch.tensor(X_train.to_numpy(), dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test.to_numpy(), dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Model and Model Hyperparameters\n",
    "    model_layers = trial.suggest_categorical(\"model_layers\", [\"3 Layers\", \"4 Layers\", \"5 Layers\"])\n",
    "    epochs = trial.suggest_int(\"epochs\", 10, 400, step=10)\n",
    "    latent_space = trial.suggest_int(\"latent_space\", 20, 200)\n",
    "\n",
    "    # k-means hyperparameters\n",
    "    # n_clusters = trial.suggest_int(\"n_clusters\", 2, 5)\n",
    "    n_clusters = 2\n",
    "\n",
    "    if model_layers == \"4 Layers\":\n",
    "        model = Autoencoder_4_Layers(input_features=X_train.shape[1], hidden_features=latent_space)\n",
    "        model, train_loss, test_loss = train_autoencoder(model=model, \n",
    "                                                         loss_fn=nn.L1Loss(), \n",
    "                                                         optimizer=torch.optim.RMSprop(model.parameters(), lr=0.00001), \n",
    "                                                         epochs=epochs, \n",
    "                                                         X_train=X_train, \n",
    "                                                         X_test=X_test, \n",
    "                                                         updates=False)\n",
    "        \n",
    "        # encode data\n",
    "        tensor_data = torch.tensor(data.to_numpy(), dtype=torch.float32).to(device) \n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            encoded_data = model.encode(tensor_data)\n",
    "\n",
    "        # convert to dataframe\n",
    "        encoded_dataframe = pd.DataFrame(encoded_data)\n",
    "\n",
    "        kmeans = KMeans(n_clusters=n_clusters)\n",
    "        cluster_labels = kmeans.fit_predict(encoded_dataframe)\n",
    "        \n",
    "        return silhouette_score(encoded_dataframe, cluster_labels)\n",
    "    \n",
    "    elif model_layers == \"3 Layers\":\n",
    "        model = Autoencoder_3_Layers(input_features=X_train.shape[1], hidden_features=latent_space)\n",
    "        model, train_loss, test_loss = train_autoencoder(model=model, \n",
    "                                                         loss_fn=nn.L1Loss(), \n",
    "                                                         optimizer=torch.optim.RMSprop(model.parameters(), lr=0.00001), \n",
    "                                                         epochs=epochs, \n",
    "                                                         X_train=X_train, \n",
    "                                                         X_test=X_test, \n",
    "                                                         updates=False)\n",
    "        \n",
    "        # encode data\n",
    "        tensor_data = torch.tensor(data.to_numpy(), dtype=torch.float32).to(device) \n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            encoded_data = model.encode(tensor_data)\n",
    "\n",
    "        # convert to dataframe\n",
    "        encoded_dataframe = pd.DataFrame(encoded_data)\n",
    "\n",
    "        kmeans = KMeans(n_clusters=n_clusters)\n",
    "        cluster_labels = kmeans.fit_predict(encoded_dataframe)\n",
    "        \n",
    "        return silhouette_score(encoded_dataframe, cluster_labels)\n",
    "    \n",
    "    elif model_layers == \"5 Layers\":\n",
    "        model = Autoencoder_5_Layers(input_features=X_train.shape[1], hidden_features=latent_space)\n",
    "        model, train_loss, test_loss = train_autoencoder(model=model, \n",
    "                                                         loss_fn=nn.L1Loss(), \n",
    "                                                         optimizer=torch.optim.RMSprop(model.parameters(), lr=0.00001), \n",
    "                                                         epochs=epochs, \n",
    "                                                         X_train=X_train, \n",
    "                                                         X_test=X_test, \n",
    "                                                         updates=False)\n",
    "        \n",
    "        # encode data\n",
    "        tensor_data = torch.tensor(data.to_numpy(), dtype=torch.float32).to(device) \n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            encoded_data = model.encode(tensor_data)\n",
    "\n",
    "        # convert to dataframe\n",
    "        encoded_dataframe = pd.DataFrame(encoded_data)\n",
    "\n",
    "        kmeans = KMeans(n_clusters=n_clusters)\n",
    "        cluster_labels = kmeans.fit_predict(encoded_dataframe)\n",
    "        \n",
    "        return silhouette_score(encoded_dataframe, cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=1000)  # Run 1000 trials\n",
    "\n",
    "# Print best results\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best silhouette score:\", study.best_value)\n",
    "\n",
    "# Save results\n",
    "df = study.trials_dataframe()\n",
    "df.to_csv(\"../Data/optuna_trials_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters that affect the objective the most\n",
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot optmisation history\n",
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel coordinates plot\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Convert study trials to DataFrame\n",
    "df = study.trials_dataframe()\n",
    "\n",
    "# Extract only completed trials\n",
    "df = df[df[\"state\"] == \"COMPLETE\"]\n",
    "\n",
    "# Rename columns for readability\n",
    "df = df.rename(columns={\"value\": \"Silhouette Score\", \"params_model_layers\": \"Model Layers\"})\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(x=\"Model Layers\", y=\"Silhouette Score\", data=df, palette=\"Set2\")\n",
    "\n",
    "# Customize plot\n",
    "plt.title(\"Silhouette Score Distribution per Model Layer\")\n",
    "plt.xlabel(\"Number of Layers\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract data from study\n",
    "trial_numbers = [t.number for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "silhouette_scores = [t.value for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "n_clusters = [t.params[\"n_clusters\"] for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sc = plt.scatter(n_clusters, silhouette_scores, c=silhouette_scores)\n",
    "\n",
    "# Customize plot\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"Silhouette Score per Number of Clusters Across Optuna Trials\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "u_stat, p_value = mannwhitneyu(df[df[\"Model Layers\"] == \"4 Layers\"][\"Silhouette Score\"], df[df[\"Model Layers\"] == \"5 Layers\"][\"Silhouette Score\"], alternative=\"two-sided\")\n",
    "print(f\"Mann-Whitney U: {u_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_stat, p_value = mannwhitneyu(df[df[\"params_n_clusters\"] == 2][\"Silhouette Score\"], df[df[\"params_n_clusters\"] == 3][\"Silhouette Score\"], alternative=\"two-sided\")\n",
    "print(f\"Mann-Whitney U: {u_stat}, p-value: {p_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tabula-muris-env)",
   "language": "python",
   "name": "tabula-muris-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
